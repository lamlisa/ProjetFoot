{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice Battle, un jeu à deux joueurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partie calculatoire \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from pulp import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> _Invariants du jeu_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pensée stratégique dépendra dans tous les cas des calculs probabilistes définis dans la première partie du rapport :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(object):\n",
    "    \n",
    "    # ******************************************** ENVISAGER UNE PARTIE *******************************************************\n",
    "    def __init__(self,N,D):\n",
    "        \n",
    "        # Paramètres de la partie : objectif de points, nombre de dés autorisés -----------------------------------------------\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Tables de stockage pour la programmation dynamique ------------------------------------------------------------------\n",
    "        self.MQ = np.ones((self.D+1,self.N+6*self.D))*np.inf \n",
    "        # MQ contiendra les Q(d,k), \n",
    "        # soit les probabilités de réaliser chaque valeur de score atteignable - hormis 1\n",
    "        # pour toutes les quantités de dés possibles.\n",
    "        self.MP = np.ones((self.D+1,self.N+6*self.D))*np.inf\n",
    "        # MP contiendra les P(d,k),\n",
    "        # c'est une version de MQ qui prend aussi en compte la possibilité d'obtenir 1.\n",
    "        # Elle est l'acteur fondateur des prises de décision.\n",
    "        \n",
    "        # MP et MQ servent aux premières phases des calculs, elles ont été créées par... purisme ? \n",
    "        # En termes d'optimisation, elles ne sont pas aussi utiles que self.MEG dans le jeu séquentiel. \n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    # *************************************************************************************************************************\n",
    "    \n",
    "    \n",
    "    # ********************************* METHODES COMMUNES A TOUTES LES VARIANTES **********************************************\n",
    "    \n",
    "    # Réfléchir en partant d'une étude probabiliste, en particulier des chances de réalisation de chaque score. ---------------\n",
    "    def Q(self,d,k):\n",
    "        \"\"\" Probabilité d'obtenir k points en lançant d dés, sachant qu'on n'a pas obtenu de 1. \"\"\"\n",
    "        if k < 2*d or k > 6*d:                                  # cas de base : scores inatteignables\n",
    "            return 0                         \n",
    "        if d == 1:                                              # cas de base : 1 chance sur 5 d'avoir 2, 3, 4, 5 ou 6 à un dé\n",
    "            return 1/5                                   \n",
    "        if self.MQ[d,k] != np.inf:                              # récupérer la valeur de Q si elle existe déjà ?\n",
    "            return self.MQ[d,k]         \n",
    "        p = np.array([self.Q(d-1,k-j) for j in range(2,7)])     # sinon, la calculer et la stocker \n",
    "        self.MQ[d,k] = np.sum(p)/5\n",
    "        return self.MQ[d,k]\n",
    "\n",
    "    def P(self,d,k):\n",
    "        \"\"\" Probabilité d'obtenir k points en lançant d dés - tout court. \"\"\"\n",
    "        if k > 1 and k < 2*d or k > 6*d+1:                      # cas de base : scores inatteignables\n",
    "            return 0             \n",
    "        if k == 1:                                              # cas de base : probabilité d'obtenir 1 quel que soit d\n",
    "            return 1-(5/6)**d                            \n",
    "        if self.MP[d,k] != np.inf:                              # récupérer la valeur de P si elle existe déjà ?\n",
    "            return self.MP[d,k]         \n",
    "        self.MP[d,k] = (5/6)**d * self.Q(d,k)                   # sinon, la calculer et la stocker\n",
    "        return self.MP[d,k]\n",
    "    \n",
    "    def allP(self):\n",
    "        \"\"\" La fonction précédente ne calcule qu'une seule case de la matrice P(d,k).\n",
    "        On s'assure ci-dessous, comme requis en 1), qu'elles se remplissent toutes. \"\"\"\n",
    "        for k in range (1,self.N+6*self.D):\n",
    "            for d in range(1,self.D+1):\n",
    "                self.MP[d,k] = self.P(d,k)\n",
    "    # -------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # *************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le décor général est posé.  \n",
    "On peut maintenant choisir entre les deux variantes du jeu : séquentiel ? simultané ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> _Variante séquentielle_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variante séquentielle contient deux méthodes majeures, un choix entre la stratégie aveugle et la stratégie optimale (avec en bonus la stratégie aléatoire). Ci-dessous, la classe qui permet de créer et d'utiliser le socle de décision adapté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(Strategy):\n",
    "    \n",
    "    # **************************************** DEFINIR UNE PARTIE EN MODE SEQUENTIEL ******************************************\n",
    "    def __init__(self,N,D):\n",
    "        \n",
    "        # charger les méthodes générales, N, D et tout ce qui s'ensuit de matrices de probabilité\n",
    "        Strategy.__init__(self,N,D) \n",
    "        \n",
    "        # Tables de stockage pour la programmation dynamique ------------------------------------------------------------------\n",
    "        self.MEG = np.ones((self.N+1,self.N+6*self.D))*np.inf\n",
    "        self.MEG[self.N-1:,:] = 1\n",
    "        self.MEG[:self.N,self.N:] = -1\n",
    "        # MEG stocke les espérances de gain d'un joueur en toute situation,\n",
    "        # à savoir, quel que soit son score actuel (indice i) et celui de son adversaire (indice j).\n",
    "        # Les scores en question peuvent théoriquement atteindre N+6D-1 si l'on arrive près de N et que l'on joue encore. \n",
    "        # Ce qu'implique la séquentialité, c'est que ce dépassement de N ne peut arriver que pour un seul des adversaires, \n",
    "        # après quoi l'autre cesse de jouer. On se permet donc de réduire l'une des deux dimensions de la matrice à N.\n",
    "        self.star = np.zeros((self.N,self.N)).astype('int')\n",
    "        # star stockera les réponses optimales des joueurs, celles qui maximisent l'espérance de gain en chaque situation.\n",
    "        # En mode stratégie optimale, c'est immédiatement à partir de star que le joueur décide de jouer un coup.\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Variables d'état ----------------------------------------------------------------------------------------------------\n",
    "        self.emptyE = True\n",
    "        # emptyE représente l'état de MEG : a-t-elle déjà été calculée ? \n",
    "        # Si oui, le calcul étant chronophage, on évitera de le refaire pour les parties suivantes sous un même N et D.\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        \n",
    "    # ************************************************ STRATEGIE AVEUGLE ******************************************************\n",
    "    \n",
    "    # Un choix paresseux : chercher à obtenir immédiatement un maximum de points. ---------------------------------------------\n",
    "\n",
    "    def scoremax(self):\n",
    "        \"\"\" Retourne le nombre de dés maximisant l'espérance du nombre de points \n",
    "        en fonction du nombre maximal de dés autorisés. \"\"\"\n",
    "        d = np.arange(self.D) + 1\n",
    "        ep = 4*d*(5/6)**d + 1 - (5/6)**d\n",
    "        return np.argmax(ep) + 1\n",
    "    \n",
    "    def blind_strategy(self,i,j):\n",
    "        \"\"\" Il suffit alors de toujours jouer la même chose. \"\"\"\n",
    "        return self.scoremax()\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # *************************************************************************************************************************\n",
    "    \n",
    "    \n",
    "    # *********************************************** STRATEGIE OPTIMALE ******************************************************\n",
    "    \n",
    "    # Grâce aux calculs de probabilités, on arrive à une stratégie plus intelligente : ----------------------------------------\n",
    "    # l'idée est maintenant d'adapter ses choix à la situation, notamment à proximité de N. -----------------------------------\n",
    "\n",
    "    def eg(self,i,j):\n",
    "        \"\"\" Calcul de l'espérance de gain du joueur 1. \n",
    "        Implique de modéliser tous les chemins possibles jusqu'à la victoire... \"\"\"\n",
    "        if self.MEG[i,j] != np.inf: \n",
    "            return self.MEG[i,j]                                # optimisation du temps de calcul par mémoïsation\n",
    "        mesesp = []                                                              \n",
    "        sesesp = []                                             # (on en profite pour regarder l'EG de l'adversaire)\n",
    "        \n",
    "        for d in range(1,self.D+1):                             # pour tous les choix de d possibles\n",
    "            monesp = 0\n",
    "            sonesp = 0\n",
    "            for k in range(1,6*d+1):                            # calculer l'espérance de gain (considérer tout score possible)\n",
    "                monesp += self.MP[d,k]* self.eg(j,i+k)          # MP a été hérité de la classe mère Strategie\n",
    "                sonesp += self.MP[d,k] * self.eg(i,j+k) \n",
    "            mesesp.append(-monesp)\n",
    "            sesesp.append(-sonesp)\n",
    "            \n",
    "        self.MEG[i,j] = np.amax(mesesp)                         # on ne retient que l'espérance maximale sur les d possibles\n",
    "        self.star[i,j] = np.argmax(mesesp)+1                    # on a ainsi trouvé le d* de la stratégie optimale\n",
    "        self.MEG[j,i] = np.amax(sesesp)                         # gain de temps : raisonnement symétrique en face de la diagonale\n",
    "        self.star[j,i] = np.argmax(sesesp)+1\n",
    "        return self.MEG[i,j]\n",
    "                \n",
    "    def allEG(self):\n",
    "        \"\"\" La fonction précédente est cantonnée à des paramètres (i,j) fixés. \n",
    "        S'assurer que MEG soit complète avant de jouer. \"\"\"\n",
    "        self.allP()                                             # une fois tous les P calculés\n",
    "        for i in range(self.N-1,-1,-1): \n",
    "            for j in range(self.N-1,-1,-1):\n",
    "                self.eg(i,j)                                    # lancer le calcul d'EG pour tous les i et j\n",
    "    \n",
    "    def optimal_strategy(self,i,j):\n",
    "        \"\"\" ... et la décision peut enfin être prise. \"\"\"\n",
    "        if self.emptyE:                                         # faire en sorte que MEG soit calculée une et une seule fois\n",
    "            self.allEG()                              \n",
    "            self.emptyE = False\n",
    "        if i==self.N-1 and j==self.N-1: return 1                # éviter les \"suicides\" juste avant l'arrivée : toujours jouer 1\n",
    "        return self.star[i,j]                                   # à un stade donné, agir de sorte à maximiser l'espérance\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # *************************************************************************************************************************\n",
    "    \n",
    "    \n",
    "    # *********************************************** STRATEGIE ALEATOIRE *****************************************************\n",
    "    \n",
    "    # Défi : trouver un mode de jeu encore plus absurde que la stratégie aveugle. ---------------------------------------------\n",
    "    def random_strategy(self,i,j):\n",
    "        return random.randint(1,self.D)\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # *************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> _Variante simultanée_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variante simultanée va compter sur un package de programmation linéaire, PULP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simultaneous(Strategy):\n",
    "    \n",
    "    # ************************************** DEFINIR UNE PARTIE EN MODE SIMULTANE *********************************************\n",
    "    def __init__(self,N,D):\n",
    "        \n",
    "        # charger les méthodes générales, N, D et tout ce qui s'ensuit de matrices de probabilité -----------------------------\n",
    "        Strategy.__init__(self,N,D)   \n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # Pour l'instant, personne n'a calculé sa stratégie optimale. ---------------------------------------------------------\n",
    "        self.clear = True \n",
    "        self.p = np.zeros((self.D))\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # CECI N'EST UTILE QUE POUR LA PARTIE OPTIONNELLE\n",
    "        # Tables de stockage pour la programmation dynamique ------------------------------------------------------------------\n",
    "        self.MEG = np.ones((self.N+6*self.D,self.N+6*self.D))*np.inf\n",
    "        self.MEG[self.N:,:] = 1\n",
    "        self.MEG[:self.N,self.N:] = -1\n",
    "        self.star = np.zeros((self.N,self.N)).astype('int')\n",
    "        self.emptyE = True\n",
    "        # Ce code est presque identique à celui qu'on trouve dans Sequential.\n",
    "        # Il n'a pas été factorisé dans la classe mère en raison de l'aspect facultatif de son traitement.\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    # *************************************************************************************************************************\n",
    "        \n",
    "        \n",
    "    # ***************************************** OPTIMISATION DU JEU EN UN COUP ************************************************\n",
    "    \n",
    "    # Partie 1 : se représenter la situation, commencer par un calcul d'espérances du point de vue d'un des joueurs. ----------\n",
    "\n",
    "    def eg1(self,d1,d2):\n",
    "        \"\"\" Retourne l'espérance de gain du joueur 1, qui joue d1 dés. \n",
    "        Le joueur 2 joue d2 dés, il ne le voit pas : les deux joueurs jouent en même temps et une seule fois. \"\"\"\n",
    "        res = 0\n",
    "        # Probabilité que le joueur 1 obtienne plus de points que le joueur 2 ?\n",
    "        for k in range(1,6*d1+1):\n",
    "            temp = 0\n",
    "            for l in range(1,k):\n",
    "                temp += self.P(d2,l)\n",
    "            res += self.P(d1,k)*temp\n",
    "        # On soustrait la probabilité que le joueur 2 obtienne plus de points que le joueur 1.\n",
    "        for k in range(1,6*d2+1):\n",
    "            temp = 0\n",
    "            for l in range(1,k):\n",
    "                temp += self.P(d1,l)\n",
    "            res -= self.P(d2,k)*temp\n",
    "        return res\n",
    "   \n",
    "    def gain_matrix(self):\n",
    "        \"\"\" Obtenir la matrice des espérances de gain du joueur 1, calculée avec la fonction eg1. \"\"\"\n",
    "        M = np.zeros((self.D,self.D))\n",
    "        for i in range(self.D):\n",
    "            for j in range(self.D):\n",
    "                M[i,j] = self.eg1(i+1,j+1)\n",
    "        return M\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # Partie 2 : le joueur 1 est désormais capable de créer sa stratégie en résolvant un programme linéaire. ------------------\n",
    "    \n",
    "    def solve_pl(self):\n",
    "        \"\"\" Renvoyer le vecteur correspondant à la stratégie du premier joueur.\n",
    "        Le PL correspondant est défini dans le rapport. \"\"\"\n",
    "        prob = LpProblem(\"Jeu en un coup\", LpMaximize) \n",
    "        # Créer les variables p1, p2, ..., pD\n",
    "        var = [LpVariable(\"p%d\" % i, lowBound=0, cat='Continuous') for i in range(1,self.D+1)]\n",
    "\n",
    "        # L'objectif est la somme des pi.\n",
    "        prob += lpSum(var)  \n",
    "        \n",
    "        eg = self.gain_matrix()\n",
    "        # Pour chaque colonne de eg, ajouter la contrainte z - transposée_de_p * colonne_de_eg <= 0 au problème.\n",
    "        for j in range(self.D): \n",
    "            l = []\n",
    "            for i in range(self.D):\n",
    "                l.append(-var[i]*eg[i,j])\n",
    "            prob += lpSum(l) <= 0\n",
    "\n",
    "        # Ajouter la contrainte sur la somme des pi à 1 (ce sont des probabilités).\n",
    "        prob += lpSum(var) == 1  \n",
    "        # La contrainte sur la positivité de chaque pi a déjà été exprimée par l'attribut lowBound.\n",
    "\n",
    "        # Lancer le calcul.\n",
    "        prob.solve()\n",
    "        prob.writeLP(\"prob\")\n",
    "        \n",
    "        # Récupérer les réponses de PULP, arrondies pour retirer les traces indésirables.\n",
    "        p = []\n",
    "        for v in var:\n",
    "            p.append(v.varValue)\n",
    "        return np.around(np.array(p),7)\n",
    "    \n",
    "    def pl_strategy(self,i,j): \n",
    "        \"\"\" Générer un d* dans une situation de score (i,j), tiré selon le retour du programme linéaire. \"\"\"\n",
    "        if self.clear:\n",
    "            # Lancer le calcul du PL si et seulement s'il n'a pas déjà été fait :\n",
    "            self.p = self.solve_pl().cumsum()\n",
    "            self.clear = False\n",
    "        # Calcul du d* (variable à chaque exécution) selon la loi générée après résolution du PL.\n",
    "        r = random.random()\n",
    "        d = 0\n",
    "        while r > self.p[d]:\n",
    "            d += 1\n",
    "        return d+1\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # *************************************************************************************************************************\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ************************************** PARTIE OPTIONNELLE : CAS GENERAL *************************************************\n",
    "    \n",
    "    # Considérer une autre façon de calculer les espérances en supposant que plusieurs tours vont être joués. -----------------\n",
    "    \n",
    "    def egg(self,i,j):\n",
    "        \"\"\" Calcul de l'espérance de gain du joueur 1 en une situation i, j,\n",
    "        en prenant en compte tous les tirages possibles pour lui et pour son adversaire. \"\"\"\n",
    "        # renvoyer les espérances qu'on connaît\n",
    "        if self.MEG[i,j] != np.inf:\n",
    "            return self.MEG[i,j]\n",
    "        # calculer celles qu'on ne connaît pas\n",
    "        monesp = -1\n",
    "        coupintelligent = 1\n",
    "        # partir pessimiste : je vais perdre, comment limiter la casse ?\n",
    "        for d1 in range (1,self.D+1):\n",
    "            maxpertes = 1\n",
    "            # chercher l'espérance de gain de l'adversaire à supposer que je joue d1 dés.\n",
    "            for d2 in range (1,self.D+1):\n",
    "                sonesp = np.sum(self.MP[d1,1:6*self.D+1].reshape(6*self.D,1)*self.MP[d2,1:6*self.D+1] * self.MEG[i+1:i+1+6*self.D,j+1:j+1+6*self.D]) \n",
    "                # peut-être a-t-il en fait moins de chances de gagner que ce que je pensais ? mettre mes croyances à jour\n",
    "                maxpertes = min(maxpertes,sonesp)\n",
    "            # choisir donc ma réponse optimale qui maximise ses pertes !\n",
    "            if (monesp < maxpertes):\n",
    "                monesp = maxpertes\n",
    "                coupintelligent = d1\n",
    "        # compléter mes matrices pour programmation dynamique\n",
    "        self.MEG[i,j] = monesp\n",
    "        self.star[i,j] = coupintelligent\n",
    "        return self.MEG[i,j]    \n",
    "    \n",
    "    def allEggs(self):\n",
    "        \"\"\" Sassurer que toutes les espérances sont déjà calculées. \"\"\"\n",
    "        self.allP()                                             # une fois tous les P calculés\n",
    "        for i in range(self.N-1,-1,-1): \n",
    "            for j in range(self.N-1,-1,-1):\n",
    "                self.egg(i,j)                                    # lancer le calcul d'EG pour tous les i et j                       \n",
    "                    \n",
    "    def simoptimal_strategy(self,i,j):\n",
    "        \"\"\" Prendre sa décision. \"\"\"\n",
    "        if self.emptyE:                                         # faire en sorte que MEG soit calculée une et une seule fois\n",
    "            self.allEggs()                              \n",
    "            self.emptyE = False\n",
    "        if i==self.N-1 and j==self.N-1: return 1                # éviter les \"suicides\" juste avant l'arrivée : toujours jouer 1\n",
    "        return self.star[i,j]                                   # à un stade donné, agir de sorte à maximiser l'espérance\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # *************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> _Annexes calculatoires_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de quelques matrices EG1 en fonction de D pour les jeux simultanés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.55111512e-17 -3.75000000e-01 -2.26851852e-01]\n",
      " [ 3.75000000e-01 -7.28583860e-17 -1.98816872e-01]\n",
      " [ 2.26851852e-01  1.98816872e-01  2.34187669e-17]]\n",
      "\n",
      " [[-5.55111512e-17 -3.75000000e-01 -2.26851852e-01 -5.07973251e-02\n",
      "   9.65577846e-02  2.19353709e-01]\n",
      " [ 3.75000000e-01 -7.28583860e-17 -1.98816872e-01 -1.16405178e-01\n",
      "   1.36424040e-02  1.26979024e-01]\n",
      " [ 2.26851852e-01  1.98816872e-01  2.34187669e-17 -1.00272920e-01\n",
      "  -4.52484377e-02  5.06845017e-02]\n",
      " [ 5.07973251e-02  1.16405178e-01  1.00272920e-01 -7.69783542e-17\n",
      "  -4.47746191e-02 -2.10626847e-03]\n",
      " [-9.65577846e-02 -1.36424040e-02  4.52484377e-02  4.47746191e-02\n",
      "   2.74845251e-17 -1.36514256e-02]\n",
      " [-2.19353709e-01 -1.26979024e-01 -5.06845017e-02  2.10626847e-03\n",
      "   1.36514256e-02  7.93127770e-17]]\n",
      "\n",
      " [[-5.55111512e-17 -3.75000000e-01 -2.26851852e-01 -5.07973251e-02\n",
      "   9.65577846e-02  2.19353709e-01  3.21683647e-01  4.06958595e-01\n",
      "   4.78021051e-01  5.37239765e-01]\n",
      " [ 3.75000000e-01 -7.28583860e-17 -1.98816872e-01 -1.16405178e-01\n",
      "   1.36424040e-02  1.26979024e-01  2.21556098e-01  3.00370822e-01\n",
      "   3.66049759e-01  4.20782207e-01]\n",
      " [ 2.26851852e-01  1.98816872e-01  2.34187669e-17 -1.00272920e-01\n",
      "  -4.52484377e-02  5.06845017e-02  1.38137758e-01  2.11547927e-01\n",
      "   2.72740350e-01  3.23734242e-01]\n",
      " [ 5.07973251e-02  1.16405178e-01  1.00272920e-01 -7.69783542e-17\n",
      "  -4.47746191e-02 -2.10626847e-03  6.98449521e-02  1.37606400e-01\n",
      "   1.94985226e-01  2.42860985e-01]\n",
      " [-9.65577846e-02 -1.36424040e-02  4.52484377e-02  4.47746191e-02\n",
      "   2.74845251e-17 -1.36514256e-02  2.23315180e-02  7.74976631e-02\n",
      "   1.30336887e-01  1.75475632e-01]\n",
      " [-2.19353709e-01 -1.26979024e-01 -5.06845017e-02  2.10626847e-03\n",
      "   1.36514256e-02  7.93127770e-17  3.36787118e-03  3.47902305e-02\n",
      "   7.79924301e-02  1.19524064e-01]\n",
      " [-3.21683647e-01 -2.21556098e-01 -1.38137758e-01 -6.98449521e-02\n",
      "  -2.23315180e-02 -3.36787118e-03 -1.95215683e-17  1.21418377e-02\n",
      "   3.98326446e-02  7.42734055e-02]\n",
      " [-4.06958595e-01 -3.00370822e-01 -2.11547927e-01 -1.37606400e-01\n",
      "  -7.74976631e-02 -3.47902305e-02 -1.21418377e-02  1.16729610e-17\n",
      "   1.61014904e-02  4.04536322e-02]\n",
      " [-4.78021051e-01 -3.66049759e-01 -2.72740350e-01 -1.94985226e-01\n",
      "  -1.30336887e-01 -7.79924301e-02 -3.98326446e-02 -1.61014904e-02\n",
      "   4.39616320e-17  1.72897008e-02]\n",
      " [-5.37239765e-01 -4.20782207e-01 -3.23734242e-01 -2.42860985e-01\n",
      "  -1.75475632e-01 -1.19524064e-01 -7.42734055e-02 -4.04536322e-02\n",
      "  -1.72897008e-02  5.20715423e-17]]\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "D = 3\n",
    "sim = Simultaneous(N,D) # à chaque fois, il nous faut instancier la classe pour avoir accès aux méthodes.\n",
    "print(sim.gain_matrix())\n",
    "\n",
    "D = 6\n",
    "sim = Simultaneous(N,D)\n",
    "print(\"\\n\",sim.gain_matrix())\n",
    "\n",
    "D = 10\n",
    "sim = Simultaneous(N,D)\n",
    "print(\"\\n\",sim.gain_matrix())\n",
    "\n",
    "# Avoir à réécrire trois lignes par test est un peu laborieux, \n",
    "# mais les fonctions et les classes sont pensées pour être utilisées en contexte de jeu,\n",
    "# elles ne sont pas très adaptées à ce genre de test.\n",
    "# L'idée, encore une fois, est que chaque partie équivaut à un état mental différent, \n",
    "# il faut donc changer de cerveau dès qu'on change de style ou de paramètres de partie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un peu choquées par la non-nullité de la diagonale, on l'explique par les approximations effectuées dans les calculs précédents ; \n",
    "on donne par exemple la preuve que les lignes de la matrice P(d,k) ne somment pas toutes exactement à 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000000000002\n",
      "1.0\n",
      "0.9999999999999999\n",
      "1.0000000000000002\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sim.allP()\n",
    "for i in range (1,sim.MP.shape[0]):\n",
    "    print(np.sum(sim.MP[i,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tente aussi de résoudre plusieurs PL pour des D différents, ce qui donne un florilège de stratégies mixtes pour le joueur 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D =  3 .   Optimal strategy for Player 1 : [0. 0. 1.]\n",
      "1.0\n",
      "\n",
      "D =  6 .   Optimal strategy for Player 1 : [0.        0.1755805 0.0529375 0.        0.771482  0.       ]\n",
      "1.0\n",
      "\n",
      "D =  10 .   Optimal strategy for Player 1 : [0.        0.1755805 0.0529375 0.        0.771482  0.        0.\n",
      " 0.        0.        0.       ]\n",
      "1.0\n",
      "\n",
      "D =  20 .   Optimal strategy for Player 1 : [0.        0.1755805 0.0529375 0.        0.771482  0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.       ]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "D = 3\n",
    "sim = Simultaneous(N,D)\n",
    "res = sim.solve_pl()\n",
    "print(\"D = \" , D, \".   Optimal strategy for Player 1 :\", res)\n",
    "print(np.sum(res)) # doit être nul, ou presque\n",
    "\n",
    "D = 6\n",
    "sim = Simultaneous(N,D)\n",
    "res = sim.solve_pl()\n",
    "print(\"\\nD = \" , D, \".   Optimal strategy for Player 1 :\", res)\n",
    "print(np.sum(res))\n",
    "\n",
    "D = 10\n",
    "sim = Simultaneous(N,D)\n",
    "res = sim.solve_pl()\n",
    "print(\"\\nD = \" , D, \".   Optimal strategy for Player 1 :\", res)\n",
    "print(np.sum(res))\n",
    "\n",
    "D = 20\n",
    "sim = Simultaneous(N,D)\n",
    "res = sim.solve_pl()\n",
    "print(\"\\nD = \" , D, \".   Optimal strategy for Player 1 :\", res)\n",
    "print(np.sum(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> _Exemples et interactions_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le support mathématique implémenté, il devient possible de conduire de vraies parties :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************** TIRAGES ET DEROULEMENT D'UNE PARTIE *************************************************\n",
    "    \n",
    "def throw(d):\n",
    "    \"\"\" Lancer les dés et simuler le score. \"\"\"\n",
    "    r = np.random.randint(1,6,d)\n",
    "    if (r == 1).sum() >= 1: return 1  \n",
    "    else: return np.sum(r)\n",
    "\n",
    "def seqgame(strat1, strat2, verbose = True, interact = False):\n",
    "    \"\"\" Jouer une partie séquentielle entre un joueur de type strat1 et un joueur de type strat2.\n",
    "    Le mode verbose permet d'afficher ou non les commentaires de jeu (on évite pour les tests).\n",
    "    Le mode interact permet d'utiliser ou non la fonction input de Python, si l'on veut se mesurer à la machine. \"\"\"\n",
    "    if interact:\n",
    "        role = input(\"Which player would you like to be ?  \")\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    round = 1\n",
    "    while score1 < N and score2 < N:                                       # tant que personne n'a gagné\n",
    "        if verbose:\n",
    "            print(\"\\nROUND\", round, \"\\t\", score1, \"to\", score2)            # faire l'état des lieux \n",
    "            print(\"=======================\")\n",
    "        if interact and int(role) == 1: \n",
    "            choix1 = input(\"Choose your warriors.  \")\n",
    "        else : choix1 = strat1(score1, score2)                             # jouer le coup suivant côté 1\n",
    "        add1 = throw(int(choix1))                                          # voir ce que le hasard décide\n",
    "        score1 += add1                                                     \n",
    "        if verbose:                              \n",
    "            print(\"Player 1 throws\", choix1, \"dice\")\n",
    "            print(\" >>> Player 1 scores\", add1)\n",
    "        if score1 < N:                                                     # continuer, à moins que 1 n'ait déjà gagné\n",
    "            if interact and int(role) == 2: \n",
    "                choix2 = input(\"Choose your warriors.  \")\n",
    "            else: choix2 = strat2(score2, score1)                          # jouer le coup suivant côté 2    \n",
    "            add2 = throw(int(choix2))                                      # voir ce que le hasard décide\n",
    "            score2 += add2 \n",
    "            if verbose:\n",
    "                print(\"Player 2 throws\", choix2, \"dice\")   \n",
    "                print(\" >>> Player 2 scores\", add2)\n",
    "        round += 1\n",
    "    if verbose: print(\"\\n! FINAL SCORE\", score1, \"to\", score2, \"!\")        # fin du jeu. afficher le gagnant.\n",
    "    if score1 >= N:                                                  \n",
    "        if verbose: print(\"Player 1 wins !\")\n",
    "        return 1                                                           # valeur de retour pour calcul du winrate\n",
    "    else:\n",
    "        if verbose: print(\"Player 2 wins !\")\n",
    "        return 0\n",
    "        \n",
    "def simgame(strat1, strat2, verbose = True, interact = False, oneround = True):\n",
    "    \"\"\" Jouer une partie simultanée entre un joueur de type strat1 et un joueur de type strat2.\n",
    "    Un nouveau paramètre, pour savoir si l'on est dans le cas général ou dans le jeu à un seul tir. \"\"\"\n",
    "    if interact:\n",
    "        role = input(\"Which player would you like to be ?  \")\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    round = 1\n",
    "    while score1 < N and score2 < N:                                       # tant que personne n'a gagné\n",
    "        if verbose:\n",
    "            print(\"\\nROUND\", round, \"\\t\", score1, \"to\", score2)            # faire l'état des lieux \n",
    "            print(\"=======================\")\n",
    "        if interact and int(role) == 1: \n",
    "            choix1 = input(\"Choose your warriors.  \")\n",
    "        else : choix1 = strat1(score1, score2)                             # jouer un coup côté 1\n",
    "        add1 = throw(int(choix1))                                          # voir ce que le hasard décide\n",
    "        oldscore1 = score1                                                 # garder une trace de l'ancien score\n",
    "        score1 += add1                                                     \n",
    "        if interact and int(role) == 2: \n",
    "            choix2 = input(\"Choose your warriors.  \")\n",
    "        else: choix2 = strat2(score2, oldscore1)                           # jouer un coup côté 2 sans savoir ce qui vient de se passer\n",
    "        add2 = throw(int(choix2))                                          # voir ce que le hasard décide\n",
    "        score2 += add2 \n",
    "        if verbose:                      \n",
    "            print(\"Player 1 threw\", choix1, \"dice\")\n",
    "            print(\" >>> Player 1 scored\", add1)\n",
    "            print(\"Player 2 threw\", choix2, \"dice\")   \n",
    "            print(\" >>> Player 2 scored\", add2)\n",
    "        round += 1\n",
    "        if oneround: break                                                 # forcer la fin du jeu s'il est en un tour\n",
    "    if verbose: print(\"\\n! FINAL SCORE\", score1, \"to\", score2, \"!\")        # fin du jeu. afficher le gagnant.\n",
    "    if score1 > score2:                                                  \n",
    "        if verbose: print(\"Player 1 wins !\")\n",
    "        return 1                                                           # valeur de retour pour calcul du winrate\n",
    "    elif score1 < score2:\n",
    "        if verbose: print(\"Player 2 wins !\")\n",
    "        return 0\n",
    "    else:\n",
    "        if verbose: print(\"Erm... Pat ?\")\n",
    "        return 1\n",
    "        \n",
    "# *****************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _définition du contexte, lancement d'un jeu séquentiel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the goal to reach ?  100\n",
      "How many dice are my friend and I allowed to use ?  10\n",
      "A game starts with 10 dice below. Whichever player reaches 100 points first wins.\n",
      "\n",
      "ROUND 1 \t 0 to 0\n",
      "=======================\n",
      "Player 1 throws 6 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 6 dice\n",
      " >>> Player 2 scores 24\n",
      "\n",
      "ROUND 2 \t 1 to 24\n",
      "=======================\n",
      "Player 1 throws 6 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 5 dice\n",
      " >>> Player 2 scores 21\n",
      "\n",
      "ROUND 3 \t 2 to 45\n",
      "=======================\n",
      "Player 1 throws 7 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 5 dice\n",
      " >>> Player 2 scores 16\n",
      "\n",
      "ROUND 4 \t 3 to 61\n",
      "=======================\n",
      "Player 1 throws 8 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 4 dice\n",
      " >>> Player 2 scores 18\n",
      "\n",
      "ROUND 5 \t 4 to 79\n",
      "=======================\n",
      "Player 1 throws 10 dice\n",
      " >>> Player 1 scores 32\n",
      "Player 2 throws 4 dice\n",
      " >>> Player 2 scores 17\n",
      "\n",
      "ROUND 6 \t 36 to 96\n",
      "=======================\n",
      "Player 1 throws 10 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 1 dice\n",
      " >>> Player 2 scores 2\n",
      "\n",
      "ROUND 7 \t 37 to 98\n",
      "=======================\n",
      "Player 1 throws 10 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 7 dice\n",
      " >>> Player 2 scores 1\n",
      "\n",
      "ROUND 8 \t 38 to 99\n",
      "=======================\n",
      "Player 1 throws 10 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 1 dice\n",
      " >>> Player 2 scores 4\n",
      "\n",
      "! FINAL SCORE 39 to 103 !\n",
      "Player 2 wins !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = int(input(\"What is the goal to reach ?  \"))\n",
    "D = int(input(\"How many dice are my friend and I allowed to use ?  \"))\n",
    "seq = Sequential(N, D) # création du socle de décision adéquat\n",
    "print(\"A game starts with\", D, \"dice below. Whichever player reaches\", N, \"points first wins.\")\n",
    "\n",
    "# Un premier exemple.\n",
    "seqgame(seq.optimal_strategy, seq.optimal_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _interaction sur un jeu séquentiel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which player would you like to be ?  1\n",
      "\n",
      "ROUND 1 \t 0 to 0\n",
      "=======================\n",
      "Choose your warriors.  4\n",
      "Player 1 throws 4 dice\n",
      " >>> Player 1 scores 1\n",
      "Player 2 throws 6 dice\n",
      " >>> Player 2 scores 24\n",
      "\n",
      "ROUND 2 \t 1 to 24\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "seqgame(seq.optimal_strategy, seq.optimal_strategy, interact = True)\n",
    "\n",
    "# Les paramètres de seqgame peuvent varier entre seq.optimal_strategy, seq.blind_strategy, seq.random_strategy.\n",
    "# Tenter de faire varier ces paramètres pour le joueur non-humain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _jeu simultané en un tour_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1 \t 0 to 0\n",
      "=======================\n",
      "Player 1 threw 5 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "! FINAL SCORE 1 to 1 !\n",
      "Erm... Pat ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = Simultaneous(N,D) # création du socle de décision adéquat\n",
    "simgame(sim.pl_strategy, seq.blind_strategy) # récupération de la stratégie aveugle sur l'autre type de jeu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _jeu simultané en plusieurs tours_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND 1 \t 0 to 0\n",
      "=======================\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 2 \t 1 to 1\n",
      "=======================\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 21\n",
      "\n",
      "ROUND 3 \t 2 to 22\n",
      "=======================\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 5 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 4 \t 3 to 23\n",
      "=======================\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 23\n",
      "Player 2 threw 5 dice\n",
      " >>> Player 2 scored 19\n",
      "\n",
      "ROUND 5 \t 26 to 42\n",
      "=======================\n",
      "Player 1 threw 7 dice\n",
      " >>> Player 1 scored 26\n",
      "Player 2 threw 5 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 6 \t 52 to 43\n",
      "=======================\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 7 \t 53 to 44\n",
      "=======================\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 22\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 8 \t 75 to 45\n",
      "=======================\n",
      "Player 1 threw 4 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 7 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 9 \t 76 to 46\n",
      "=======================\n",
      "Player 1 threw 4 dice\n",
      " >>> Player 1 scored 12\n",
      "Player 2 threw 7 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 10 \t 88 to 47\n",
      "=======================\n",
      "Player 1 threw 3 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 8 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 11 \t 89 to 48\n",
      "=======================\n",
      "Player 1 threw 3 dice\n",
      " >>> Player 1 scored 11\n",
      "Player 2 threw 10 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "! FINAL SCORE 100 to 49 !\n",
      "Player 1 wins !\n",
      "45.85056209564209\n"
     ]
    }
   ],
   "source": [
    "a=time.time()\n",
    "simgame(sim.simoptimal_strategy, sim.simoptimal_strategy, oneround = False)\n",
    "print(time.time()-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _interaction sur un jeu simultané en plusieurs tours_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which player would you like to be ?  1\n",
      "\n",
      "ROUND 1 \t 0 to 0\n",
      "=======================\n",
      "Choose your warriors.  6\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 20\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 2 \t 20 to 1\n",
      "=======================\n",
      "Choose your warriors.  6\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 3 \t 21 to 2\n",
      "=======================\n",
      "Choose your warriors.  6\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 4 \t 22 to 3\n",
      "=======================\n",
      "Choose your warriors.  5\n",
      "Player 1 threw 5 dice\n",
      " >>> Player 1 scored 14\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 5 \t 36 to 4\n",
      "=======================\n",
      "Choose your warriors.  5\n",
      "Player 1 threw 5 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 7 dice\n",
      " >>> Player 2 scored 24\n",
      "\n",
      "ROUND 6 \t 37 to 28\n",
      "=======================\n",
      "Choose your warriors.  4\n",
      "Player 1 threw 4 dice\n",
      " >>> Player 1 scored 17\n",
      "Player 2 threw 6 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 7 \t 54 to 29\n",
      "=======================\n",
      "Choose your warriors.  4\n",
      "Player 1 threw 4 dice\n",
      " >>> Player 1 scored 16\n",
      "Player 2 threw 8 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 8 \t 70 to 30\n",
      "=======================\n",
      "Choose your warriors.  4\n",
      "Player 1 threw 4 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 9 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 9 \t 71 to 31\n",
      "=======================\n",
      "Choose your warriors.  3\n",
      "Player 1 threw 3 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 9 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 10 \t 72 to 32\n",
      "=======================\n",
      "Choose your warriors.  2\n",
      "Player 1 threw 2 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 9 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 11 \t 73 to 33\n",
      "=======================\n",
      "Choose your warriors.  3\n",
      "Player 1 threw 3 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 9 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 12 \t 74 to 34\n",
      "=======================\n",
      "Choose your warriors.  6\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 9 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 13 \t 75 to 35\n",
      "=======================\n",
      "Choose your warriors.  6\n",
      "Player 1 threw 6 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 9 dice\n",
      " >>> Player 2 scored 33\n",
      "\n",
      "ROUND 14 \t 76 to 68\n",
      "=======================\n",
      "Choose your warriors.  5\n",
      "Player 1 threw 5 dice\n",
      " >>> Player 1 scored 1\n",
      "Player 2 threw 8 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 15 \t 77 to 69\n",
      "=======================\n",
      "Choose your warriors.  4\n",
      "Player 1 threw 4 dice\n",
      " >>> Player 1 scored 16\n",
      "Player 2 threw 8 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "ROUND 16 \t 93 to 70\n",
      "=======================\n",
      "Choose your warriors.  3\n",
      "Player 1 threw 3 dice\n",
      " >>> Player 1 scored 11\n",
      "Player 2 threw 8 dice\n",
      " >>> Player 2 scored 1\n",
      "\n",
      "! FINAL SCORE 104 to 71 !\n",
      "Player 1 wins !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simgame(sim.simoptimal_strategy, sim.simoptimal_strategy, interact = True, oneround = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> _Tests statistiques_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables communes à tous les tests : jouer nb_parties d'un type de match donné\n",
    "# ns et ds servent à créer les graduations du graphique\n",
    "nb_parties = 10000\n",
    "ns = np.arange(20, 220, 20)\n",
    "ds = np.arange(2,22,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _jeu séquentiel_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit maintenant d'évaluer nos stratégies, d'abord selon l'objectif à atteindre, en fixant D = 10 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aveugle contre aveugle : mode séquentiel\n",
    "winrates_n_bb = np.zeros((10))\n",
    "winrates_d_bb = np.zeros((10))\n",
    "# Optimale contre optimale : mode séquentiel\n",
    "winrates_n_oo = np.zeros((10))\n",
    "winrates_d_oo = np.zeros((10))\n",
    "# Optimale contre aveugle : mode séquentiel\n",
    "winrates_n_ob = np.zeros((10))\n",
    "winrates_d_ob = np.zeros((10))\n",
    "# Aveugle contre optimale : mode séquentiel\n",
    "winrates_n_bo = np.zeros((10))\n",
    "winrates_d_bo = np.zeros((10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range (20,220,20):\n",
    "    N = n\n",
    "    seq = Sequential(n,10)\n",
    "    resbb = np.sum(np.array([seqgame(seq.blind_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    resoo = np.sum(np.array([seqgame(seq.optimal_strategy,seq.optimal_strategy,False) for i in range(nb_parties)]))\n",
    "    resob = np.sum(np.array([seqgame(seq.optimal_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    resbo = np.sum(np.array([seqgame(seq.blind_strategy,seq.optimal_strategy,False) for i in range(nb_parties)]))\n",
    "    winrates_n_bb[int((n-20)/20)] = resbb/nb_parties\n",
    "    winrates_n_oo[int((n-20)/20)] = resoo/nb_parties\n",
    "    winrates_n_ob[int((n-20)/20)] = resob/nb_parties\n",
    "    winrates_n_bo[int((n-20)/20)] = resbo/nb_parties\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(ns, winrates_n_bb, 'c--', ns, winrates_n_oo, 'b--', ns, winrates_n_ob, 'g--', ns, winrates_n_bo, 'y--', ns, np.full(ns.shape,0.5),'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puis selon le nombre de dés autorisés, en fixant l'objectif N = 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range (2,22,2):\n",
    "    N = 100\n",
    "    seq = Sequential(100,d)\n",
    "    resbb = np.sum(np.array([seqgame(seq.blind_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    resoo = np.sum(np.array([seqgame(seq.optimal_strategy,seq.optimal_strategy,False) for i in range(nb_parties)]))\n",
    "    resob = np.sum(np.array([seqgame(seq.optimal_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    resbo = np.sum(np.array([seqgame(seq.blind_strategy,seq.optimal_strategy,False) for i in range(nb_parties)]))\n",
    "    winrates_d_bb[int((d-2)/2)] = resbb/nb_parties\n",
    "    winrates_d_oo[int((d-2)/2)] = resoo/nb_parties\n",
    "    winrates_d_ob[int((d-2)/2)] = resob/nb_parties\n",
    "    winrates_d_bo[int((d-2)/2)] = resbo/nb_parties\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ds, winrates_d_bb, 'c--', ds, winrates_d_oo, 'b--', ds, winrates_d_ob, 'g--', ds, winrates_d_bo, 'y--', ds, np.full(ns.shape,0.5),'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche aussi à évaluer la stratégie aléatoire par rapport aux deux autres : puisqu'on se doute qu'elle va perdre, on lui laisse l'avantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aléatoire contre aveugle : mode séquentiel\n",
    "winrates_n_ab = np.zeros((10))\n",
    "winrates_d_ab = np.zeros((10))\n",
    "# Aléatoire contre optimale : mode séquentiel\n",
    "winrates_n_ao = np.zeros((10))\n",
    "winrates_d_ao = np.zeros((10))\n",
    "    \n",
    "for n in range (20,220,20):\n",
    "    N = n\n",
    "    seq = Sequential(n,10)\n",
    "    resab = np.sum(np.array([seqgame(seq.random_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    resao = np.sum(np.array([seqgame(seq.random_strategy,seq.optimal_strategy,False) for i in range(nb_parties)]))\n",
    "    winrates_n_ab[int((n-20)/20)] = resab/nb_parties\n",
    "    winrates_n_ao[int((n-20)/20)] = resao/nb_parties\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ns, winrates_n_ab, 'r--', ns, winrates_n_ao, 'm--', ns, np.full(ns.shape,0.5),'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range (2,22,2):\n",
    "    N = 100\n",
    "    seq = Sequential(100,d)\n",
    "    resab = np.sum(np.array([seqgame(seq.random_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    resao = np.sum(np.array([seqgame(seq.random_strategy,seq.optimal_strategy,False) for i in range(nb_parties)]))\n",
    "    winrates_d_ab[int((d-2)/2)] = resab/nb_parties\n",
    "    winrates_d_ao[int((d-2)/2)] = resao/nb_parties\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ds, winrates_d_ab, 'r--', ds, winrates_d_ao, 'm--', ds, np.full(ns.shape,0.5),'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _jeu simultané_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le jeu simultané, on teste comme requis en 14) la solidité de la stratégie pl-optimale face à la stratégie aveugle.  \n",
    "Il n'y a plus de relation d'ordre entre les joueurs, donc un seul test par paramètre varié suffit pour les comparer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimale contre aveugle : mode simultané\n",
    "winrates_n_plb = np.zeros((10))\n",
    "winrates_d_plb = np.zeros((10))\n",
    "\n",
    "for n in range (20,220,20):\n",
    "    N = n\n",
    "    seq = Sequential(n,10)\n",
    "    sim = Simultaneous(n,10)\n",
    "    resplb = np.sum(np.array([simgame(sim.pl_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    winrates_n_plb[int((n-20)/20)] = resplb/nb_parties\n",
    "plt.figure()\n",
    "plt.plot(ns, winrates_n_plb, 'c--', ns, np.full(ns.shape,0.5),'k')\n",
    "plt.show()\n",
    "\n",
    "N = 100\n",
    "for d in range (2,22,2):\n",
    "    seq = Sequential(N,d)\n",
    "    sim = Simultaneous(N,d)\n",
    "    resplb = np.sum(np.array([simgame(sim.pl_strategy,seq.blind_strategy,False) for i in range(nb_parties)]))\n",
    "    winrates_d_plb[int((d-2)/2)] = resplb/nb_parties\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(ds, winrates_d_plb, 'c--', ds, np.full(ns.shape,0.5),'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code du programme linéaire pour la onzième question :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Optimum= 0.21935370941929572\n",
      "x1 = 1.0\n",
      "x2 = 0.0\n",
      "x3 = 0.0\n",
      "x4 = 0.0\n",
      "x5 = 0.0\n",
      "x6 = 0.0\n",
      "x7 = 0.0\n",
      "x8 = 0.0\n",
      "x9 = 0.0\n",
      "x10 = 0.0\n"
     ]
    }
   ],
   "source": [
    "q = np.zeros(D)\n",
    "q[min(6,D)-1]=1\n",
    "s = Simultaneous(10,D)\n",
    "eg = s.gain_matrix()\n",
    "eg_q = eg.dot(q)\n",
    "\n",
    "prob = LpProblem(\"Détermination de q\", LpMaximize)\n",
    "var = [LpVariable(\"x%d\" % i,lowBound=0,cat='Continuous') for i in range(1,D+1)]\n",
    "\n",
    "temp = []\n",
    "for j in range(D):\n",
    "    temp.append(lpSum([var(i)*eg[i,j] for i in range(D)]))\n",
    "    \n",
    "prob += lpSum([temp[i]*eg_q[i] for i in range(D)])\n",
    "prob += lpSum(var) == 1 \n",
    "\n",
    "prob.solve()\n",
    "prob.writeLP(\"prob\")\n",
    "\n",
    "print(\"Total Optimum=\", value(prob.objective)) # doit être nul\n",
    "\n",
    "for v in var:\n",
    "    print(v.name, \"=\", v.varValue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
